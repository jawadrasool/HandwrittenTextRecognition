{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the packages required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2513,
     "status": "ok",
     "timestamp": 1531246264868,
     "user": {
      "displayName": "Ahmed Saleh Mansour",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117595413341319589091"
     },
     "user_tz": -120
    },
    "id": "BJh1TM2o5IRi",
    "outputId": "1ee821cd-b641-4a39-cc4d-342bdf7b7a3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps \n",
    "from skimage.util.shape import view_as_windows\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization, Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two packages will be used to evaluate the performance of the prediction.\n",
    "# from the distance package we will use the editdistance which calculate the minimum number of string operation\n",
    "# required to match two strings. On the other hand the SequenceMatcher function is a similarity measure function for\n",
    "# two strings that gives a number between 0 and 1 where 1 means two exact strings\n",
    "! pip install distance \n",
    "from difflib import SequenceMatcher\n",
    "import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the CTC loss function and the Model (Copied from Training file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jntIROXl6E2N"
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PFVqwCff5IRp"
   },
   "outputs": [],
   "source": [
    "timeSteps = 277\n",
    "window_h  = 64\n",
    "window_w  = 32\n",
    "Char_Num  = 80\n",
    "seq_len   = 90\n",
    "    \n",
    "input_lines = Input(shape=(timeSteps, window_h, window_w, 1), name='the_input')\n",
    "\n",
    "Conv_1 = TimeDistributed(Conv2D(16, (3,3), padding= 'same'),name=\"Conv_1\")(input_lines)\n",
    "Acti_1 = TimeDistributed(Activation(\"relu\"),name=\"Acti_1\")(Conv_1)\n",
    "Pool_1 = TimeDistributed(MaxPooling2D(pool_size=(2, 1)),name=\"Pool_1\")(Acti_1)\n",
    "Norm_1 = TimeDistributed(BatchNormalization(),name=\"Norm_1\")(Pool_1)\n",
    "\n",
    "Conv_2 = TimeDistributed(Conv2D(32, (3,3), padding= 'same'),name=\"Conv_2\")(Norm_1)\n",
    "Acti_2 = TimeDistributed(Activation(\"relu\"),name=\"Acti_2\")(Conv_2)\n",
    "Pool_2 = TimeDistributed(MaxPooling2D(pool_size=(2, 2)),name=\"Pool_2\")(Acti_2)\n",
    "Norm_2 = TimeDistributed(BatchNormalization(),name=\"Norm_2\")(Pool_2)\n",
    "\n",
    "Conv_3 = TimeDistributed(Conv2D(64, (3,3), padding= 'same'),name=\"Conv_3\")(Norm_2)\n",
    "Acti_3 = TimeDistributed(Activation(\"relu\"),name=\"Acti_3\")(Conv_3)\n",
    "Pool_3 = TimeDistributed(MaxPooling2D(pool_size=(2, 2)),name=\"Pool_3\")(Acti_3)\n",
    "Norm_3 = TimeDistributed(BatchNormalization(),name=\"Norm_3\")(Pool_3)\n",
    "Drop_3 = TimeDistributed(Dropout(0.2),name=\"Drop_3\")(Norm_3)\n",
    "\n",
    "Conv_4 = TimeDistributed(Conv2D(128, (3,3), padding= 'same'),name=\"Conv_4\")(Drop_3)\n",
    "Acti_4 = TimeDistributed(Activation(\"relu\"),name=\"Acti_4\")(Conv_4)\n",
    "Pool_4 = TimeDistributed(MaxPooling2D(pool_size=(2, 2)),name=\"Pool_4\")(Acti_4)\n",
    "Norm_4 = TimeDistributed(BatchNormalization(),name=\"Norm_4\")(Pool_4)\n",
    "Drop_4 = TimeDistributed(Dropout(0.25),name=\"Drop_4\")(Norm_4)\n",
    "\n",
    "Conv_5 = TimeDistributed(Conv2D(256, (3,3), padding= 'same'),name=\"Conv_5\")(Drop_4)\n",
    "Acti_5 = TimeDistributed(Activation(\"relu\"),name=\"Acti_5\")(Conv_5)\n",
    "Pool_5 = TimeDistributed(MaxPooling2D(pool_size=(2, 2)),name=\"Pool_5\")(Acti_5)\n",
    "Norm_5 = TimeDistributed(BatchNormalization(),name=\"Norm_5\")(Pool_5)\n",
    "Drop_5 = TimeDistributed(Dropout(0.3),name=\"Drop_5\")(Norm_5)\n",
    "\n",
    "Flat_1 = TimeDistributed(Flatten(),name=\"Flat_1\")(Drop_5)\n",
    "Dens_1 = TimeDistributed(Dense(256,activation='relu',name='Dens_1'))(Flat_1)\n",
    "\n",
    "lstm_1 = LSTM(256, return_sequences=True, name='lstm_1')(Dens_1)\n",
    "lstm_1b = LSTM(256, return_sequences=True, go_backwards=True, name='lstm_1b')(Dens_1)\n",
    "lstm1_merged = add([lstm_1, lstm_1b])\n",
    "lstm_2 = LSTM(256, return_sequences=True, name='lstm_2')(lstm1_merged)\n",
    "lstm_2b = LSTM(256, return_sequences=True, go_backwards=True, name='lstm_2b')(lstm1_merged)\n",
    "\n",
    "Dens_f = Dense(Char_Num, name='Dens_f')(concatenate([lstm_2, lstm_2b]))\n",
    "Acti_f = Activation('softmax',name=\"Acti_f\")(Dens_f)    #y_pred\n",
    "\n",
    "labels = Input(name='the_labels', shape=[seq_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([Acti_f, labels, input_length, label_length])\n",
    "\n",
    "line_model = Model(inputs=[input_lines, labels, input_length, label_length], outputs=loss_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and load the weights of the trained model and define the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MxzGYbux5IRt"
   },
   "outputs": [],
   "source": [
    "# Although we saved the whole model, we can not directly use save model because keras will have a problem as our model\n",
    "# uses a lambda function as the minimizing loss function. To overcome this issue we have to create the whole model \n",
    "# again then use the saved trained model to set the weights. Finally we define that our predictind model takes the\n",
    "# input lines and outputs the matrix from the classification (dense - activation layer). Remeber that this layer will \n",
    "# be of length equals to the timesteps and some transformation is need to compress it to the coresponding text length.\n",
    "\n",
    "line_model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='rmsprop')\n",
    "line_model.load_weights('Moving_Window_Models/Model.17.hdf5')\n",
    "predict_model = Model(inputs=input_lines, outputs=Acti_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methode to transform the output classes into a text by defined a reverse dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "51xcY-WA5IRx"
   },
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    \n",
    "    alphabet = {' ': 0 , '!': 1, '\"': 2, '#': 3, \"&\": 4, \"'\": 5, '(': 6, ')': 7, '*': 8, '+': 9, ',': 10, '-': 11,\n",
    "             '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22,\n",
    "             '9': 23, ':': 24, ';': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33,\n",
    "             'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44,\n",
    "             'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55,\n",
    "             'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66,\n",
    "             'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, \n",
    "             'z': 78}\n",
    "\n",
    "    reverse_alphabet = dict((i, char) for char, i in alphabet.items())\n",
    "    \n",
    "    res = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            res.append(\"\")\n",
    "        else:\n",
    "            res.append(reverse_alphabet[c])\n",
    "    return \"\".join(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation of the image to pe passed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tBLF_5K75IR0"
   },
   "outputs": [],
   "source": [
    "# it is important to highlight that our model was created and trained to handle gray scale images, so it can only\n",
    "# be used for this type of images. Thus before passing the image to this function, the user has to make sure that the\n",
    "# image is a gray sclae image with dimension of width*height and that the value range is between 0 and 255. \n",
    "# Please note that some gray scale images are usually saved as boolean with true and false for black and white, while\n",
    "# others are saved as binary images with only 0 and 1. Thus it is the responsibility of the user of this model to \n",
    "# prepare the images by himself at first.\n",
    "\n",
    "def get_features_predict (image_file):\n",
    "    # This function is also taken exactly from the training part where we only consider the preparation of the image\n",
    "    # as no label preparation is needed during prediction\n",
    "    \n",
    "    def_h = 64                      \n",
    "    def_w = 2240                    \n",
    "    max_word_length = 90            \n",
    "    window_w = 32                   \n",
    "    window_step = 8                \n",
    "    window_size = (def_h,window_w)\n",
    "    \n",
    "    im = Image.open(image_file)\n",
    "    im_w,im_h = im.size \n",
    "    \n",
    "    im_arr = np.array(im)\n",
    "    im_arr[im_arr<=200] = 0\n",
    "    im_arr[im_arr>200] = 255\n",
    "    im = Image.fromarray(im_arr)  \n",
    "\n",
    "    im = im.resize((im_w*def_h/im_h,def_h),Image.LANCZOS)\n",
    "    im_w,im_h = im.size \n",
    "    if im_w <= def_w-10:\n",
    "        im = ImageOps.expand(im,border=(5,0,5,0),fill='white')\n",
    "        im = ImageOps.expand(im,border=(0,0,def_w-im_w-10,0),fill='black')\n",
    "    else:\n",
    "        im = im.resize((def_w,def_h),Image.LANCZOS)\n",
    "    assert(im.size==(def_w,def_h))\n",
    "    \n",
    "    im_arr = np.array(im)/255.0\n",
    "    im_windows_array = view_as_windows(im_arr, window_size, step = window_step)[0]\n",
    "    \n",
    "    return im_windows_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding the output of the model using CTC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u1EXtyyC5IR7"
   },
   "outputs": [],
   "source": [
    "# The CTC decoder is a very powerfull tool it takes the output of the activation layer (batchsize_predict, timesteps, \n",
    "# num_classes). In our case we have only 1 image for each prediction and timesteps is 277 and num_classes is 80 which \n",
    "# corresponds to the 79 characters that we have in the alphabet dictionary + an additional character which is the \n",
    "# character ignored by the CTC 'blank label have id -1'. We use the decoding with greedy = True which return the \n",
    "# most probable path only. There another variation where greedy is set to False, however in that case it is advised\n",
    "# to pass an external dictionary that constraints the decoding so certain words, in that case the the decoder will \n",
    "# return a set of top_paths probable output sequences. We think that it might be a good way to improve the decoding\n",
    "# capability of the model. However, it is not an easy extension because at the moment both the Keras and tensorflow\n",
    "# implementations of the CTC_decode function doesnot have this option and we have to implement it ourselves. There \n",
    "# seems to be an implementation on github https://github.com/githubharald/CTCWordBeamSearch but it is only for tensorflow\n",
    "# Anyway, this might be a good direction for enhancing our results.\n",
    "\n",
    "def decode_predict_ctc(out, top_paths = 1):\n",
    "    results = []\n",
    "    beam_width = 5\n",
    "    if beam_width < top_paths:\n",
    "        beam_width = top_paths\n",
    "    for i in range(top_paths):\n",
    "        lables = K.get_value(K.ctc_decode(out, input_length=np.ones(out.shape[0])*out.shape[1],\n",
    "                           greedy=True, beam_width=beam_width, top_paths=top_paths)[0][i])[0]\n",
    "        text = labels_to_text(lables)\n",
    "        results.append(text)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uoGDfGc95IST",
    "outputId": "e6c6b491-1f7d-4a13-cb5c-d15c71e1d784"
   },
   "outputs": [],
   "source": [
    "test_image = 'lines/g04/g04-026/g04-026-00.png'\n",
    "\n",
    "timeSteps = 277\n",
    "window_h  = 64\n",
    "window_w  = 32\n",
    "Channels = 1\n",
    "\n",
    "X_curr = get_features_predict (test_image)\n",
    "X_predict = np.ones([1, timeSteps, window_h, window_w, Channels])\n",
    "X_predict[0,:,:,:,0] = X_curr     \n",
    "net_out_value = predict_model.predict(X_predict)\n",
    "pred_texts = decode_predict_ctc(net_out_value)\n",
    "\n",
    "Sequ_Siml = SequenceMatcher(None,pred_texts[0], text).ratio()\n",
    "Edit_dist = distance.levenshtein(text, pred_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity and Edit distance measure on Training lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dPjDDLkxu1sI"
   },
   "outputs": [],
   "source": [
    "0.508923186643\n",
    "22.2311178248\n",
    "Model_01          662 samples\n",
    "\n",
    "0.7942032981\n",
    "9.92145015106\n",
    "Model_02          662 samples\n",
    "\n",
    "0.856698319518\n",
    "7.01208459215\n",
    "Model_03          662 samples\n",
    "\n",
    "0.897841427648\n",
    "5.10574018127\n",
    "Model_04          662 samples\n",
    "\n",
    "0.91086792963\n",
    "4.43051359517\n",
    "Model_05          662 samples\n",
    "\n",
    "0.913104716847\n",
    "4.38066465257\n",
    "Model_06          662 samples\n",
    "\n",
    "0.93418817595\n",
    "3.31117824773\n",
    "Model_07          662 samples\n",
    "\n",
    "0.945191130963\n",
    "2.83232628399\n",
    "Model_08          662 samples\n",
    "\n",
    "0.938934974773\n",
    "3.00755287009\n",
    "Model_09          662 samples\n",
    "\n",
    "0.943225273913\n",
    "2.96525679758\n",
    "Model_10          662 samples\n",
    "\n",
    "0.95160941778\n",
    "2.48489425982\n",
    "Model_11          662 samples\n",
    "\n",
    "0.957841669587\n",
    "2.16012084592\n",
    "Model_12          662 samples\n",
    "\n",
    "0.968514753688\n",
    "1.6586102719\n",
    "Model_13          662 samples\n",
    "\n",
    "0.984877178248\n",
    "0.820241691843\n",
    "Model_14          662 samples\n",
    "\n",
    "0.987583568244\n",
    "0.688821752266\n",
    "Model_15          662 samples\n",
    "\n",
    "0.989319410784\n",
    "0.616314199396\n",
    "Model_16          662 samples\n",
    "\n",
    "0.989877622172\n",
    "0.569486404834\n",
    "Model_17          662 samples  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity and Edit distance measure on Test lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1531210700857,
     "user": {
      "displayName": "Ahmed Saleh Mansour",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "117595413341319589091"
     },
     "user_tz": -120
    },
    "id": "sBdEPM2n5LFJ",
    "outputId": "ce2e83f4-ef9c-4c5f-b4ad-f0d4b8ca04c6"
   },
   "outputs": [],
   "source": [
    "0.501957501476\n",
    "22.6963746224\n",
    "Model_01       Full Data\n",
    "\n",
    "0.784521773509\n",
    "10.5453172205\n",
    "Model_02       Full Data\n",
    "\n",
    "0.843822981689\n",
    "7.80966767372\n",
    "Model_3        Full Data\n",
    "\n",
    "0.882099479777\n",
    "5.95770392749\n",
    "Model_4        Full Data\n",
    "\n",
    "0.891063369234\n",
    "5.45317220544\n",
    "Model_5       Full Data\n",
    "\n",
    "0.892110061667\n",
    "5.58912386707\n",
    "Model_6       Full Data\n",
    "\n",
    "0.908403082921\n",
    "4.64803625378\n",
    "Model_7       Full Data\n",
    "\n",
    "0.917260130158\n",
    "4.24773413897\n",
    "Model_08      Full Data\n",
    "\n",
    "0.906333122088\n",
    "4.57401812689\n",
    "Model_09       Full Data\n",
    "\n",
    "0.908946897993\n",
    "4.59516616314\n",
    "Model_10       Full Data\n",
    "\n",
    "0.912874817945\n",
    "4.43655589124\n",
    "Model_11       Full Data\n",
    "\n",
    "0.916891944741\n",
    "4.13444108761\n",
    "Model_12       Full Data\n",
    "\n",
    "0.927065501785\n",
    "3.68126888218\n",
    "Model_13       Full Data\n",
    "\n",
    "0.940975214411\n",
    "3.02870090634\n",
    "Model_14       Full Data\n",
    "\n",
    "0.941144969955\n",
    "2.99848942598\n",
    "Model_15       Full Data\n",
    "\n",
    "0.941704667352\n",
    "2.95770392749\n",
    "Model_16       Full Data\n",
    "\n",
    "0.942238338125\n",
    "2.93957703927\n",
    "Model_17       Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uTLtHXqLRdxz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "CTC_Saleh_Predict.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
