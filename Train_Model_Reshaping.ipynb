{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KTj2b9pGXA2Z"
   },
   "source": [
    "# Importing all the packages required for our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8367,
     "status": "ok",
     "timestamp": 1530913559549,
     "user": {
      "displayName": "Safia Akbar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106832037845572532314"
     },
     "user_tz": -120
    },
    "id": "ync98ddLXA2o",
    "outputId": "317d1511-89c4-41c9-e802-48d6e3a00850"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from PIL import Image, ImageOps \n",
    "import distance\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store results\n",
    "OUTPUT_DIR = 'Reshape_Model_Weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the text label into a category label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XDJgITjbXA3I"
   },
   "outputs": [],
   "source": [
    "# character classes and matching regex filter\n",
    "alphabet = {' ': 0 , '!': 1, '\"': 2, '#': 3, \"&\": 4, \"'\": 5, '(': 6, ')': 7, '*': 8, '+': 9, ',': 10, '-': 11,\n",
    "             '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22,\n",
    "             '9': 23, ':': 24, ';': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33,\n",
    "             'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44,\n",
    "             'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55,\n",
    "             'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66,\n",
    "             'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, \n",
    "             'z': 78}\n",
    "\n",
    "reverse_alphabet = dict((i, char) for char, i in alphabet.items())\n",
    "\n",
    "# Translation of characters to unique integer values\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet[char])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating each batch used to fit our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YZ-IF4bYXA3P"
   },
   "outputs": [],
   "source": [
    "# Uses generator functions to supply train/test with data. \n",
    "class TextImageGenerator(keras.callbacks.Callback):\n",
    "  \n",
    "    def __init__(self, run_name, minibatch_size, img_w, img_h, downsample_factor, absolute_max_string_len, train_samples, val_samples):\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.blank_label = self.get_output_size() - 1\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "        self.train_samples = train_samples\n",
    "        self.val_samples = val_samples\n",
    "        \n",
    "        self.output_dir = os.path.join(OUTPUT_DIR + os.sep, run_name)\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return len(alphabet) + 1\n",
    "\n",
    "    def build_Data(self, csv_train, csv_val): \n",
    "        \n",
    "        self.data_train = pd.read_csv(csv_train).sample(self.train_samples)\n",
    "        self.data_val = pd.read_csv(csv_val).sample(self.val_samples)\n",
    "        \n",
    "        self.image_dir = 'lines/'\n",
    "        \n",
    "        self.cur_train_index = 0\n",
    "        self.cur_val_index = 0\n",
    "        \n",
    "    def get_batch(self, index, size, train):\n",
    "        X_data = np.ones([size, self.img_w, self.img_h, 1])\n",
    "        labels = np.ones([size, self.absolute_max_string_len]) * -1\n",
    "        input_length = np.zeros([size, 1])\n",
    "        label_length = np.zeros([size, 1])\n",
    "        \n",
    "        if train:\n",
    "            data = self.data_train.loc[index:index+size-1]\n",
    "        else:\n",
    "            data = self.data_val.loc[index:index+size-1]\n",
    "          \n",
    "        i = 0\n",
    "        for path,text in zip(data.Path,data.Text):\n",
    "            X_curr, Y_curr = get_features_label(self.image_dir + path,text, self.img_h, self.img_w)\n",
    "            X_data[i, 0:self.img_w, :, 0] = X_curr.T\n",
    "            labels[i, 0:len(Y_curr)] = Y_curr\n",
    "            input_length[i] = self.img_w // self.downsample_factor #- 2\n",
    "            label_length[i] = len(Y_curr)\n",
    "            i = i + 1\n",
    "            \n",
    "        inputs = {'the_input': X_data,\n",
    "                  'the_labels': labels,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': source_str  # used for visualization only\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([size])}  # dummy data for dummy loss function\n",
    "        return (inputs, outputs)\n",
    "\n",
    "    def next_train(self):\n",
    "        while True:\n",
    "            ret = self.get_batch(self.cur_train_index, self.minibatch_size, train=True)\n",
    "            self.cur_train_index += self.minibatch_size\n",
    "            if self.cur_train_index >= self.train_samples:\n",
    "                self.cur_train_index = self.cur_train_index % self.minibatch_size\n",
    "            yield ret\n",
    "\n",
    "    def next_val(self):\n",
    "        while True:\n",
    "            ret = self.get_batch(self.cur_val_index, self.minibatch_size, train=False)\n",
    "            self.cur_val_index += self.minibatch_size\n",
    "            if self.cur_val_index >= self.val_samples:\n",
    "                self.cur_val_index = self.cur_val_index % self.minibatch_size\n",
    "            yield ret\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        csv_train = 'Train_Lines.csv'\n",
    "        csv_val = 'Test_Lines.csv'\n",
    "        self.build_Data(csv_train, csv_val)\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        #print (\"-------------------------------------------------------\")\n",
    "        pass\n",
    "      \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 3 == 0:\n",
    "            self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NGc5yzm-XA3Y"
   },
   "outputs": [],
   "source": [
    "def get_features_label (image_file,repres, h, w):\n",
    "    #defining some hyperparameters\n",
    "    def_h = h                   # We have set it to 64, might also conider 128 or even 32\n",
    "    def_w = w                   # calculated form the data\n",
    "    num_char_per_seq = 90       # max is 87 then we append spaces at the end untill we reach 90 \n",
    "    \n",
    "    # We first read the image and perform the binary thresholding. We choose the threshold to be 200 \n",
    "    # based on some investigation. However, this is a hyperparmeter that can be tuned  \n",
    "    im = Image.open(image_file)\n",
    "    im_w,im_h = im.size \n",
    "    \n",
    "    im_arr = np.array(im)\n",
    "    im_arr[im_arr<=200] = 0\n",
    "    im_arr[im_arr>200] = 1\n",
    "    im = Image.fromarray(im_arr*255)    \n",
    "\n",
    "    # We now resize the image to the desired height while keeping the same aspect ratio.\n",
    "    # We then pad the image to reach the maximum width\n",
    "    im_w,im_h = im.size \n",
    "    im = im.resize((im_w*def_h//im_h,def_h),Image.LANCZOS)\n",
    "    im_w,im_h = im.size \n",
    "    \n",
    "    # We pad the smaller images so that all images have equal dimensions\n",
    "    if im_w < def_w:\n",
    "        im = ImageOps.expand(im,border=(0,0,6,0),fill='white')\n",
    "        im = ImageOps.expand(im,border=(0,0,def_w-im_w-6,0),fill='black')\n",
    "    # Just in case, if we get an image with width higher than our width, we shrink it. \n",
    "    elif im_w > def_w:\n",
    "        im = im.resize((def_w,def_h),Image.LANCZOS)\n",
    "    assert(im.size==(def_w,def_h))\n",
    "    \n",
    "    # Normalize your pixels to either zero or one \n",
    "    im_arr = np.array(im)/255\n",
    "    \n",
    "    # create your labels\n",
    "    label = text_to_labels(repres)\n",
    "            \n",
    "    return im_arr, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the CTC loss function from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uoESjBmEXA3f"
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1226
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3518,
     "status": "ok",
     "timestamp": 1530913576382,
     "user": {
      "displayName": "Safia Akbar",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106832037845572532314"
     },
     "user_tz": -120
    },
    "id": "URsXc0oF-h21",
    "outputId": "cb763d63-eb4e-488c-b415-d66581ccbdd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 2120, 64, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 2120, 64, 16) 160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 1060, 32, 16) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "BN1 (BatchNormalization)        (None, 1060, 32, 16) 64          max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 1060, 32, 32) 4640        BN1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1060, 32, 32) 0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 530, 16, 32)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "BN2 (BatchNormalization)        (None, 530, 16, 32)  128         max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 530, 16, 48)  13872       BN2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 530, 16, 48)  0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max3 (MaxPooling2D)             (None, 265, 8, 48)   0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "BN3 (BatchNormalization)        (None, 265, 8, 48)   192         max3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 265, 8, 64)   27712       BN3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 265, 8, 64)   0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "BN4 (BatchNormalization)        (None, 265, 8, 64)   256         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 265, 8, 80)   46160       BN4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "BN5 (BatchNormalization)        (None, 265, 8, 80)   320         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 265, 640)     0           BN5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 265, 256)     164096      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 265, 256)     525312      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm1_b (LSTM)                  (None, 265, 256)     525312      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 265, 256)     0           lstm1[0][0]                      \n",
      "                                                                 lstm1_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm2 (LSTM)                    (None, 265, 256)     525312      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm2_b (LSTM)                  (None, 265, 256)     525312      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 265, 512)     0           lstm2[0][0]                      \n",
      "                                                                 lstm2_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 265, 80)      41040       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 265, 80)      0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,399,888\n",
      "Trainable params: 2,399,408\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input Parameters\n",
    "img_h = 64 \n",
    "img_w = 2120 #calculated from the actual data after rescaling to height 64\n",
    "len_alphabets = len(alphabet)+1\n",
    "num_char_per_seq = 90\n",
    "\n",
    "# Network parameters\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 256\n",
    "rnn_size = 256\n",
    "minibatch_size = 64\n",
    "act = 'relu'\n",
    "    \n",
    "input_shape = (img_w, img_h, 1)\n",
    "\n",
    "# The input layer of our model: \n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "#First Conv_Layer\n",
    "X = Conv2D(16, kernel_size, padding='same', activation=act, kernel_initializer='he_normal', name='conv1')(input_data)\n",
    "X = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(X)\n",
    "X = BatchNormalization(name=\"BN1\")(X)\n",
    "\n",
    "#Second Conv_Layer\n",
    "X = Conv2D(32, kernel_size, padding='same', activation=act, kernel_initializer='he_normal', name='conv2')(X)\n",
    "X = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(X)\n",
    "X = BatchNormalization(name=\"BN2\")(X)\n",
    "X = Dropout(0.1)(X)\n",
    "\n",
    "#Third Conv_Layer\n",
    "X = Conv2D(48, kernel_size, padding='same', activation=act, kernel_initializer='he_normal', name='conv3')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = MaxPooling2D(pool_size=(pool_size, pool_size), name='max3')(X)\n",
    "X = BatchNormalization(name=\"BN3\")(X)\n",
    "\n",
    "#Fourth Conv_Layer\n",
    "X = Conv2D(64, kernel_size, padding='same', activation=act, kernel_initializer='he_normal', name='conv4')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = BatchNormalization(name=\"BN4\")(X)\n",
    "\n",
    "#Fifth Conv_Layer\n",
    "X = Conv2D(80, kernel_size, padding='same', activation=act, kernel_initializer='he_normal', name='conv5')(X)\n",
    "X = BatchNormalization(name=\"BN5\")(X)\n",
    "\n",
    "# One of the techniques used to connect CNN with LSTM is the concept of reshaping the input to the \n",
    "# dimensions expected by the LSTM i.e. (sample, time_steps, features). Here, \"sample\" is the size of \n",
    "# your minibatch, \"time_steps\" is the length of a sequence, since recurrent neural network are \n",
    "# designed to process time-series, and \"features\" is the dimension of each element of the time-series.\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 3), (img_h // (pool_size ** 3)) * 80)\n",
    "X = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(X)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "X = Dense(time_dense_size, activation=act, name='dense1')(X)\n",
    "\n",
    "# We have a bidiretional LSTM network that consists of two LSTMs, where each of them takes the input and consume it\n",
    "# from a diferent direction (forward and backward). We then take the output of the two LSTMs and merged together. We \n",
    "# then passe the merged output to another bidirectional LSTM network. We then take the output of these two LSTMS and\n",
    "# concatenate it together then passe it to out finall classifing dense lasyer.\n",
    "\n",
    "# First layer of bidirectional LSTMs\n",
    "lstm_1 = LSTM(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(X)\n",
    "lstm_1b = LSTM(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(X)\n",
    "\n",
    "# adding the output of the two LSTMS of the previous layer\n",
    "lstm1_merged = add([lstm_1, lstm_1b])\n",
    "\n",
    "# Second layer of bidirectional LSTMs\n",
    "lstm_2 = LSTM(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "lstm_2b = LSTM(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "X = Dense(len_alphabets, kernel_initializer='he_normal', name='dense2')(concatenate([lstm_2, lstm_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(X)\n",
    "\n",
    "# According to the previous model we will have a decided class for each timestep. Now the idea is to define a function\n",
    "# that will compress these classified windows into the length of the text seqence. For this we use the predefined CTC\n",
    "# loss function, which takes the output of the classification layer, the true label, the length of the classifing layer\n",
    "# output (timesteps) and the length of the label sequence (original text)\n",
    "\n",
    "labels = Input(name='the_labels', shape=[num_char_per_seq], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "# Keras doesn't currently support loss funcs with extra parameters so CTC loss is implemented in a lambda layer\n",
    "# This will be our loss function that our optimizer should aim to minimize it\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# Define an optimzer\n",
    "rms = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "# We finally define our model and show its summary\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0e_vvgIgXA4L"
   },
   "outputs": [],
   "source": [
    "def train(run_name, start_epoch, stop_epoch):\n",
    "    \n",
    "    train_samples = 12352  # needs to be a multiple of batch size in current implementation\n",
    "    val_samples =  640   # needs to be a multiple of batch size in current implementation\n",
    "    \n",
    "    assert train_samples % minibatch_size == 0\n",
    "    assert val_samples % minibatch_size == 0\n",
    "        \n",
    "    img_gen = TextImageGenerator(run_name = run_name, minibatch_size=minibatch_size,\n",
    "                                 img_w=img_w,\n",
    "                                 img_h=img_h,\n",
    "                                 downsample_factor=(pool_size ** 3),\n",
    "                                 absolute_max_string_len = num_char_per_seq, \n",
    "                                 train_samples=train_samples, val_samples=val_samples\n",
    "                                 )\n",
    "        \n",
    "    # we compile the model using rmsprop as an optimizer and CTC as the loss function\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=rms)\n",
    "    \n",
    "    #If we want to use existing weights, they need to be defined here\n",
    "    \n",
    "    #run_name = '2018_06_29_15_33_15'\n",
    "    #weight = 'weights33.h5'\n",
    "    #weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, weight)) \n",
    "    #model.load_weights(weight_file)\n",
    "    \n",
    "    model.fit_generator(generator=img_gen.next_train(),\n",
    "                        steps_per_epoch=train_samples // minibatch_size,\n",
    "                        epochs=stop_epoch,\n",
    "                        validation_data=img_gen.next_val(),\n",
    "                        validation_steps=val_samples // minibatch_size,\n",
    "                        callbacks=[img_gen],\n",
    "                        initial_epoch=start_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R3W2jnOnleXC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 26.9931 - val_loss: 28.3032\n",
      "Epoch 36/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 23.1395 - val_loss: 27.0307\n",
      "Epoch 37/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 20.8303 - val_loss: 26.3673\n",
      "Epoch 38/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 18.8440 - val_loss: 23.8388\n",
      "Epoch 39/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 17.1342 - val_loss: 23.4031\n",
      "Epoch 40/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 16.1048 - val_loss: 22.2064\n",
      "Epoch 41/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 14.6368 - val_loss: 20.5394\n",
      "Epoch 42/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 13.6434 - val_loss: 20.8540\n",
      "Epoch 43/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 12.7652 - val_loss: 20.3403\n",
      "Epoch 44/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 11.7526 - val_loss: 20.1657\n",
      "Epoch 45/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 10.9676 - val_loss: 20.2094\n",
      "Epoch 46/155\n",
      "193/193 [==============================] - 443s 2s/step - loss: 10.1882 - val_loss: 20.1132\n",
      "Epoch 47/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 9.8215 - val_loss: 18.9167\n",
      "Epoch 48/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 8.9034 - val_loss: 20.6384\n",
      "Epoch 49/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 8.3221 - val_loss: 20.4537\n",
      "Epoch 50/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 7.8162 - val_loss: 19.7899\n",
      "Epoch 51/155\n",
      "193/193 [==============================] - 442s 2s/step - loss: 7.3001 - val_loss: 19.5668\n",
      "Epoch 52/155\n",
      "193/193 [==============================] - 443s 2s/step - loss: 6.7676 - val_loss: 21.2888\n",
      "Epoch 53/155\n",
      "193/193 [==============================] - 443s 2s/step - loss: 6.5174 - val_loss: 20.1390\n",
      "Epoch 54/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 5.9898 - val_loss: 20.1136\n",
      "Epoch 55/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 5.7017 - val_loss: 20.2073\n",
      "Epoch 56/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 5.2989 - val_loss: 20.1213\n",
      "Epoch 57/155\n",
      "193/193 [==============================] - 443s 2s/step - loss: 5.0572 - val_loss: 19.9489\n",
      "Epoch 58/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 4.7293 - val_loss: 21.4323\n",
      "Epoch 59/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 4.5095 - val_loss: 20.6508\n",
      "Epoch 60/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 4.2590 - val_loss: 20.4029\n",
      "Epoch 61/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 4.0767 - val_loss: 20.6629\n",
      "Epoch 62/155\n",
      "193/193 [==============================] - 442s 2s/step - loss: 3.7694 - val_loss: 22.8802\n",
      "Epoch 63/155\n",
      "193/193 [==============================] - 443s 2s/step - loss: 3.6195 - val_loss: 20.2840\n",
      "Epoch 64/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 3.4180 - val_loss: 21.8236\n",
      "Epoch 65/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 3.2658 - val_loss: 22.5464\n",
      "Epoch 66/155\n",
      "193/193 [==============================] - 443s 2s/step - loss: 3.1554 - val_loss: 21.3224\n",
      "Epoch 67/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 2.9745 - val_loss: 22.1028\n",
      "Epoch 68/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 2.8430 - val_loss: 21.9207\n",
      "Epoch 69/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 2.7109 - val_loss: 22.4819\n",
      "Epoch 70/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 2.6225 - val_loss: 22.4047\n",
      "Epoch 71/155\n",
      "193/193 [==============================] - 448s 2s/step - loss: 2.5605 - val_loss: 23.1962\n",
      "Epoch 72/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 2.4420 - val_loss: 22.7792\n",
      "Epoch 73/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 2.2981 - val_loss: 22.2892\n",
      "Epoch 74/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 2.2347 - val_loss: 23.5461\n",
      "Epoch 75/155\n",
      "193/193 [==============================] - 447s 2s/step - loss: 2.2197 - val_loss: 22.9089\n",
      "Epoch 76/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 2.1366 - val_loss: 23.7131\n",
      "Epoch 77/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 2.0614 - val_loss: 24.2603\n",
      "Epoch 78/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 2.0325 - val_loss: 23.6646\n",
      "Epoch 79/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 1.9332 - val_loss: 22.9916\n",
      "Epoch 80/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 1.8509 - val_loss: 24.1671\n",
      "Epoch 81/155\n",
      "193/193 [==============================] - 445s 2s/step - loss: 1.8317 - val_loss: 23.2263\n",
      "Epoch 82/155\n",
      "193/193 [==============================] - 444s 2s/step - loss: 1.7735 - val_loss: 23.8315\n",
      "Epoch 83/155\n",
      " 42/193 [=====>........................] - ETA: 5:40 - loss: 1.7439"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9b9c57787c26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2018_07_07_134248_FullData'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-8c35f64a7768>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run_name, start_epoch, stop_epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mviz_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                         initial_epoch=start_epoch)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_name = '2018_07_07_134248_FullData'\n",
    "train(run_name, 34, 155)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Using_CTC_180706.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
